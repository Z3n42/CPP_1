Vagrant.configure("2") do |config|
  # Detect the Vagrant provider
  # HELP: vagrant up --provider=vmware_desktop or vagrant up --provider=virtualbox
  provider = (ARGV.find { |a| a.start_with?("--provider=") }&.split("=")&.last) || ENV["VAGRANT_DEFAULT_PROVIDER"] || "virtualbox"

  # Check if cleanup should run based on an environment variable
  # HELP: DESTROY_ALL=true vagrant destroy -f
  destroy_all = ENV["DESTROY_ALL"] == "true"

  # Detect the host architecture
  host_arch = RbConfig::CONFIG["host_cpu"].downcase

  # Define the synced folder path
  synced_folder_path = File.expand_path("./vagrant_shared")

  # Define VM's
  server_name = "migarcia"
  agent_name = "ingonzal"

  puts "üîç Using CPU architecture: #{host_arch}"
  puts "üîç Using provider: #{provider}"

  # Ensure the folder exists before Vagrant starts
  config.trigger.before :up do |t|
    t.only_on = server_name
    t.info = "üìÇ Creating synced folder: #{synced_folder_path}"

    t.ruby do |env, machine|
      require 'fileutils'
      if !File.directory?(synced_folder_path)
        FileUtils.mkdir_p(synced_folder_path)
      else
        env.ui.detail("üìÇ Directory already exists: #{synced_folder_path}")
      end
    end
  end

  # Force SSH to use only the specified identity
  config.ssh.insert_key = true
  config.ssh.forward_agent = true
  config.ssh.extra_args = ["-o", "IdentitiesOnly=yes"]

  # Choose box based on the architecture
  # /arm|aarch64/ Only for development issues
  case host_arch
  when /x64|x86_64/
    config.vm.box = "migarcia-ingonzal/IOT_Alpine_3.22"
    config.vm.box_version = "2025.06.08"
  when /arm|aarch64/
    config.vm.box = "spox/ubuntu-arm"
    config.vm.box_version = "1.0.0"
  else
    abort "Unsupported architecture: #{host_arch}"
  end

  # Configure the provider
  case provider
  when "vmware_desktop"
    config.vm.provider "vmware_desktop" do |vmware|
      vmware.allowlist_verified = true
      vmware.vmx["ethernet0.pcislotnumber"] = "160"
      vmware.vmx["memsize"] = "512"
      vmware.vmx["numvcpus"] = "1"
      # vmware.vmx["ethernet0.virtualDev"] = "e1000"
      vmware.vmx["ethernet0.connectionType"] = "nat"
    end
    # Shared folder vmware
    config.vm.synced_folder "./vagrant_shared", "/home/vagrant/shared", mount_options: ["umask=000"]
  when "virtualbox"
    config.vm.provider "virtualbox" do |vb|
      vb.customize ["modifyvm", :id, "--memory", "1024"]
      vb.customize ["modifyvm", :id, "--cpus", "1"]
      vb.customize ["modifyvm", :id, "--nic1", "nat"]
      vb.customize ["modifyvm", :id, "--paravirtprovider", "kvm"]
      vb.customize ["modifyvm", :id, "--cpuexecutioncap", "80"]
    end
    # Shared folder VirtualBox
    config.vm.synced_folder "./vagrant_shared", "/home/vagrant/shared", mount_options: ["dmode=775", "fmode=664"]
  else
    abort "Unsupported provider: #{provider}"
  end

 if Vagrant.has_plugin?("vagrant-vbguest")
    config.vbguest.auto_update = false
  end

  # Define the Server node (migarcia)
  config.vm.provision "shell", inline: <<-SHELL
    echo "nameserver 8.8.8.8" > /etc/resolv.conf
  SHELL

  config.vm.define server_name do |s|
    s.vm.network "private_network", ip: "192.168.56.110", hostname: true
    s.vm.hostname = "#{server_name}S"

    # Ensure passwordless SSH
    s.vm.provision "shell", inline: <<-SHELL
      echo "üîë Setting up passwordless SSH on migarcia..."
      echo 'PasswordAuthentication no' >> /etc/ssh/sshd_config
      echo 'PermitRootLogin no' >> /etc/ssh/sshd_config
      rc-service sshd restart
    SHELL

    # Install K3s and configure kubeconfig
    s.vm.provision "shell", inline: <<-SHELL
      echo "üåê Checking internet connectivity..."
      if ! ping -4 -c 4 google.com &> /dev/null; then
        echo "‚ùå Error: No internet connectivity"
        exit 1
      fi

      echo "üîç Installing K3s in controller mode..."
      curl -sfL https://get.k3s.io | INSTALL_K3S_EXEC="server --tls-san 192.168.56.110 --write-kubeconfig-mode=644 --write-kubeconfig=/home/vagrant/shared/kubeconfig.yaml" sh -
  
      # Verify the installation
      if [ $? -ne 0 ]; then
        echo "‚ùå Error: K3s installation failed"
        exit 1
      fi
  
      # Wait until files are created
      echo "‚è≥ Waiting for K3s to start..."
      timeout 42 sh -c 'until rc-service k3s status | grep -q "started"; do sleep 2; done'
      timeout 42 sh -c 'until [ -S /run/k3s/containerd/containerd.sock ]; do sleep 2; done'
      timeout 42 sh -c 'until [ -f /home/vagrant/shared/kubeconfig.yaml ]; do sleep 2; done'
  
      if [ ! -f /home/vagrant/shared/kubeconfig.yaml ]; then
        echo "‚ùå Error: kubeconfig.yaml not found"
        exit 1
      fi

      if [ ! -f /var/lib/rancher/k3s/server/node-token ]; then
        echo "‚ùå Error: node-token not found"
        exit 1
      fi

      echo "üîß Updating kubeconfig to use external IP..."
      sed -i 's|127.0.0.1|192.168.56.110|g' /home/vagrant/shared/kubeconfig.yaml
      # Copy the node-token for workers
      cp /var/lib/rancher/k3s/server/node-token /home/vagrant/shared/node-token
    SHELL
  end

  # Define the client node (ingonzal)
  config.vm.define agent_name do |sw|
    sw.vm.network "private_network", ip: "192.168.56.111", hostname: true
    sw.vm.hostname = "#{agent_name}SW"

    # Ensure passwordless SSH
    sw.vm.provision "shell", inline: <<-SHELL
      echo "üîë Setting up passwordless SSH on ingonzal..."
      echo 'PasswordAuthentication no' >> /etc/ssh/sshd_config
      echo 'PermitRootLogin no' >> /etc/ssh/sshd_config
      rc-service sshd restart
    SHELL

    # Install K3s and configure kubeconfig
    sw.vm.provision "shell", inline: <<-SHELL
      echo "üîç Installing K3s in agent mode..."
      TIMEOUT=60
      ELAPSED=0
      
      # Wait until the controller token is available
      while [ ! -f /home/vagrant/shared/node-token ]; do
        echo "‚è≥ Waiting for controller token... ($ELAPSED/$TIMEOUT seconds)"
        sleep 2
        ELAPSED=$((ELAPSED + 2))

        if [ "$ELAPSED" -ge "$TIMEOUT" ]; then
          echo "‚ùå Timeout: node-token not found after $TIMEOUT seconds."
          exit 1
        fi
      done
      
      # Wait
      echo "‚è≥ Waiting for connectivity..."
      timeout 42 sh -c 'until nc -zv 192.168.56.110 6443; do sleep 5; done'
    
      TOKEN=$(cat /home/vagrant/shared/node-token)
      curl -sfL https://get.k3s.io | INSTALL_K3S_EXEC="agent --server https://192.168.56.110:6443 --token $TOKEN --node-label node.kubernetes.io/worker=true" sh -
    
      # Worker kubeconfig
      mkdir -p /home/vagrant/.kube
      cp /home/vagrant/shared/kubeconfig.yaml /home/vagrant/.kube/config
      export KUBECONFIG="/home/vagrant/.kube/config"

      # Worker ROLE 
      echo "üîç Setting worker role..."
      HOSTNAME=$(hostname | tr '[:upper:]' '[:lower:]')
      timeout 420 sh -c 'until kubectl get node $HOSTNAME >/dev/null 2>&1; do sleep 5; done' && \
      kubectl label node $HOSTNAME node-role.kubernetes.io/worker=true --overwrite
    
      echo "‚úÖ K3s agent instalado correctamente en ingonzalSW."
    SHELL
  end

  # Removing synced folder and .vagrant directory if Run 'DESTROY_ALL=true vagrant destroy -f'
  config.trigger.after :destroy do |t|
    if ENV["DESTROY_ALL"] == "true"
      t.only_on = server_name
      t.info = "üóëÔ∏è Checking if all machines are destroyed before removing synced folder..."
      
      t.ruby do |env, machine|
        sleep 5
        
        output = `vagrant global-status --prune 2>/dev/null | grep running | wc -l`.strip
        remaining_vms = output.to_i
        
        if remaining_vms == 0
          env.ui.info("üóëÔ∏è Removing synced folder and .vagrant directory...")
          require 'fileutils'
          FileUtils.rm_rf(synced_folder_path) if File.directory?(synced_folder_path)
          FileUtils.rm_rf(".vagrant") if File.directory?(".vagrant")
        else
          env.ui.info("üìå Not removing synced folder yet, there are still active machines.")
        end
      end
    else
      t.info = "üö´ Skipping cleanup: Run 'DESTROY_ALL=true vagrant destroy -f' to remove synced folder."
    end
  end
end
